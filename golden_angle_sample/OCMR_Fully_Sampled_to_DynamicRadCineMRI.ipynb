{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OCMR Fully Sampled to DynamicRadCineMRI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CARDIAL-nyu/cmr-playground/blob/main/golden_angle_sample/OCMR_Fully_Sampled_to_DynamicRadCineMRI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Google Drive for storage"
      ],
      "metadata": {
        "id": "yEzxsLbgrgCW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3lqKy1HFoYt"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{sys.executable} -m pip install torch==1.6.0 torchvision torchtext torchkbnufft==0.3.4"
      ],
      "metadata": {
        "id": "T3kMvoTY45EJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!{sys.executable} -m pip freeze"
      ],
      "metadata": {
        "id": "ipvaOEx1yTL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies"
      ],
      "metadata": {
        "id": "A8Kr4651roys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib notebook\n",
        "\n",
        "# Generic scientific python\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import cupy as cp\n",
        "import pandas as pd\n",
        "\n",
        "# Aesthetics\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "plt.style.use('fivethirtyeight')\n",
        "five_thirty_eight = [\n",
        "\"#30a2da\",\n",
        "\"#fc4f30\",\n",
        "\"#e5ae38\",\n",
        "\"#6d904f\",\n",
        "\"#8b8b8b\",\n",
        "]\n",
        "sns.set_palette(five_thirty_eight, color_codes=True)\n",
        "sns.set_color_codes()\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "\n",
        "# ISMRM Tools\n",
        "import sys\n",
        "!{sys.executable} -m pip install git+https://github.com/ismrmrd/ismrmrd-python-tools.git git+https://github.com/ismrmrd/ismrmrd-python.git --no-binary ismrmrd\n",
        "import ismrmrdtools\n",
        "import ismrmrdtools.coils\n",
        "import ismrmrd\n",
        "import ismrmrd.xsd\n",
        "from ismrmrdtools import show, transform\n",
        "\n",
        "# AWS and other MRI tools\n",
        "!{sys.executable} -m pip install boto3==1.19.12 watermark\n",
        "\n",
        "# AWS\n",
        "import boto3\n",
        "from botocore import UNSIGNED\n",
        "from botocore.client import Config\n",
        "\n",
        "# Progress Bar\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from tqdm import tnrange as trange\n",
        "\n",
        "# Standard library\n",
        "import glob\n",
        "import itertools\n",
        "import tempfile\n",
        "import datetime\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# MRI libraries\n",
        "!{sys.executable} -m pip install sigpy h5py git+https://github.com/mritools/mrrt.mri.git\n",
        "import sigpy as sp\n",
        "import sigpy.plot as pl\n",
        "import sigpy.mri as mri\n",
        "from mrrt.mri.coils import coil_pca, apply_pca_weights\n",
        "\n",
        "# Visualization\n",
        "from IPython.core.display import HTML, Video\n",
        "import matplotlib.animation as animation\n",
        "from skimage import exposure\n",
        "\n",
        "# DynamicRadCineMRI requires these older library versions pinned here:\n",
        "#!{sys.executable} -m pip install torch==1.6.0 torchkbnufft==0.3.4"
      ],
      "metadata": {
        "id": "fSVNRxbjGClS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!{sys.executable} -m pip freeze"
      ],
      "metadata": {
        "id": "tIBDp-Bqya3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utility Functions\n",
        "## Major utilities\n",
        " - `read_ocmr` based off of sample code that accompanies OCMR data\n",
        " - `return_ekg_from_ismrmrd` extracts EKG from the ISMRMRD file if available\n",
        " - `view_cine` displays an HTML5 video player for visualizing cine"
      ],
      "metadata": {
        "id": "QeVWkumdsLym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_ocmr(filename, extrareturns=False):\n",
        "# Before running the code, install ismrmrd-python and ismrmrd-python-tools:\n",
        "#  https://github.com/ismrmrd/ismrmrd-python\n",
        "#  https://github.com/ismrmrd/ismrmrd-python-tools\n",
        "# Last modified: 06-12-2020 by Chong Chen (Chong.Chen@osumc.edu)\n",
        "#\n",
        "# Input:  *.h5 file name\n",
        "# Output: all_data    k-space data, orgnazide as {'kx'  'ky'  'kz'  'coil'  'phase'  'set'  'slice'  'rep'  'avg'}\n",
        "#         param  some parameters of the scan\n",
        "# \n",
        "\n",
        "# This is a function to read K-space from ISMRMD *.h5 data\n",
        "# Modifid by Chong Chen (Chong.Chen@osumc.edu) based on the python script\n",
        "# from https://github.com/ismrmrd/ismrmrd-python-tools/blob/master/recon_ismrmrd_dataset.py\n",
        "\n",
        "    if not os.path.isfile(filename):\n",
        "        print(\"%s is not a valid file\" % filename)\n",
        "        raise SystemExit\n",
        "    dset = ismrmrd.Dataset(filename, 'dataset', create_if_needed=False)\n",
        "    header = ismrmrd.xsd.CreateFromDocument(dset.read_xml_header())\n",
        "    enc = header.encoding[0]\n",
        "\n",
        "    # Matrix size\n",
        "    eNx = enc.encodedSpace.matrixSize.x\n",
        "    #eNy = enc.encodedSpace.matrixSize.y\n",
        "    eNz = enc.encodedSpace.matrixSize.z\n",
        "    eNy = (enc.encodingLimits.kspace_encoding_step_1.maximum + 1); #no zero padding along Ny direction\n",
        "\n",
        "    # Field of View\n",
        "    eFOVx = enc.encodedSpace.fieldOfView_mm.x\n",
        "    eFOVy = enc.encodedSpace.fieldOfView_mm.y\n",
        "    eFOVz = enc.encodedSpace.fieldOfView_mm.z\n",
        "    \n",
        "    # Save the parameters    \n",
        "    param = dict();\n",
        "    param['TRes'] =  str(header.sequenceParameters.TR)\n",
        "    param['FOV'] = [eFOVx, eFOVy, eFOVz]\n",
        "    param['TE'] = str(header.sequenceParameters.TE)\n",
        "    param['TI'] = str(header.sequenceParameters.TI)\n",
        "    param['echo_spacing'] = str(header.sequenceParameters.echo_spacing)\n",
        "    param['flipAngle_deg'] = str(header.sequenceParameters.flipAngle_deg)\n",
        "    param['sequence_type'] = header.sequenceParameters.sequence_type\n",
        "\n",
        "    # Read number of Slices, Reps, Contrasts, etc.\n",
        "    nCoils = header.acquisitionSystemInformation.receiverChannels\n",
        "    try:\n",
        "        nSlices = enc.encodingLimits.slice.maximum + 1\n",
        "    except:\n",
        "        nSlices = 1\n",
        "        \n",
        "    try:\n",
        "        nReps = enc.encodingLimits.repetition.maximum + 1\n",
        "    except:\n",
        "        nReps = 1\n",
        "               \n",
        "    try:\n",
        "        nPhases = enc.encodingLimits.phase.maximum + 1\n",
        "    except:\n",
        "        nPhases = 1;\n",
        "\n",
        "    try:\n",
        "        nSets = enc.encodingLimits.set.maximum + 1;\n",
        "    except:\n",
        "        nSets = 1;\n",
        "\n",
        "    try:\n",
        "        nAverage = enc.encodingLimits.average.maximum + 1;\n",
        "    except:\n",
        "        nAverage = 1;   \n",
        "        \n",
        "    firstacq=0\n",
        "    noise_scan = list()\n",
        "    for acqnum in trange(dset.number_of_acquisitions()):\n",
        "        acq = dset.read_acquisition(acqnum)\n",
        "\n",
        "        # TODO: Currently ignoring noise scans\n",
        "        if acq.isFlagSet(ismrmrd.ACQ_IS_NOISE_MEASUREMENT):\n",
        "            #print(\"Found noise scan at acq \", acqnum)\n",
        "            noise_scan.append(dset.read_acquisition(acqnum).data)\n",
        "            continue\n",
        "        else:\n",
        "            firstacq = acqnum\n",
        "            print(\"Imaging acquisition starts acq \", acqnum)\n",
        "            break\n",
        "     \n",
        "    noise_scan = np.asarray(noise_scan)\n",
        "\n",
        "    # assymetry echo\n",
        "    kx_prezp = 0;\n",
        "    acq_first = dset.read_acquisition(firstacq)\n",
        "    if  acq_first.center_sample*2 <  eNx:\n",
        "        kx_prezp = eNx - acq_first.number_of_samples\n",
        "         \n",
        "    # Initialiaze a storage array\n",
        "    param['kspace_dim'] = {'kx ky kz coil phase set slice rep avg'};\n",
        "    all_data = np.zeros((eNx, eNy, eNz, nCoils, nPhases, nSets, nSlices, nReps, nAverage), dtype=np.complex64)\n",
        "\n",
        "    # Loop through the rest of the acquisitions and stuff\n",
        "    for acqnum in trange(firstacq,dset.number_of_acquisitions()):\n",
        "        acq = dset.read_acquisition(acqnum)\n",
        "\n",
        "        # Stuff into the buffer\n",
        "        y = acq.idx.kspace_encode_step_1\n",
        "        z = acq.idx.kspace_encode_step_2\n",
        "        phase =  acq.idx.phase;\n",
        "        set =  acq.idx.set;\n",
        "        slice =  acq.idx.slice;\n",
        "        rep =  acq.idx.repetition;\n",
        "        avg = acq.idx.average;        \n",
        "        all_data[kx_prezp:, y, z, :,phase, set, slice, rep, avg ] = np.transpose(acq.data)\n",
        "        \n",
        "    try:\n",
        "        twix_ekg = return_ekg_from_ismrmrd(dset)\n",
        "    except:\n",
        "        twix_ekg = None\n",
        "        print('EKG not found in data')\n",
        "\n",
        "    if not extrareturns:\n",
        "        return all_data, param\n",
        "    else:\n",
        "        return all_data, param, enc, acq_first, noise_scan, twix_ekg\n",
        "    \n",
        "def return_ekg_from_ismrmrd(f):\n",
        "    \"\"\"\n",
        "    returns dataframe with dset passed in\n",
        "    \"\"\"\n",
        "    nwaveforms = f.number_of_waveforms()\n",
        "    read_waveforms = [f.read_waveform(i) for i in trange(nwaveforms, desc='Reading waveforms...') if\n",
        "                      f.read_waveform(i).waveform_id == 0]\n",
        "\n",
        "    # List comprehension above puts them in an odd format. This re-arranges to fit nicely into pandas DataFrame.\n",
        "    x1 = np.hstack((read_waveforms[0].data, read_waveforms[1].data))\n",
        "    for a_stack in tqdm(read_waveforms[2:], desc='Stacking waveforms...'):\n",
        "        x1 = np.hstack((x1, a_stack.data))\n",
        "\n",
        "    # Siemens twix files have EKG recorded at sampling rate of 400 Hz. Create the time array:\n",
        "    t1 = np.arange(0, x1.shape[1]) / 400.0\n",
        "\n",
        "    return pd.DataFrame(np.vstack((t1, x1)).T,\n",
        "                        columns=['time_sec', 'ch1', 'ch2', 'ch3', 'ch4', 'isTrigger_boolean'])\n",
        "\n",
        "def return_xyt_array(filename):\n",
        "    recon_tv_1 = cfl.readcfl(filename.replace('.cfl','').replace('.hdr',''))\n",
        "    recon_tv_sqz_1 = recon_tv_1[:,:,0,0,0,0,0,0,0,0,:].squeeze()\n",
        "    return recon_tv_sqz_1[::-1,:,:].transpose((1,0,2))\n",
        "\n",
        "def view_cine(filename, display_now=True, fig_width=7, fps=10, equalize=True):\n",
        "    if isinstance(filename, str):\n",
        "        xyt_array = return_xyt_array(filename)\n",
        "    else:\n",
        "        xyt_array = filename\n",
        "        filename = id(filename)\n",
        "\n",
        "    _cine_html_out_f, _ani_out_f = cine_html5(xyt_array, fig_width=fig_width, equalize=equalize);\n",
        "    if display_now:\n",
        "        display(_cine_html_out_f)\n",
        "    else:\n",
        "        with open(f'{filename}.html', 'w') as f:\n",
        "            f.write(_ani_out_f.to_jshtml(fps=fps, default_mode='loop'))\n",
        "        print(f'HTML of cine saved at: {f\"{filename}.html\"}')\n",
        "    \n",
        "def equalize_xyt(xyt_array):\n",
        "    if xyt_array.shape[1] < xyt_array.shape[0]:\n",
        "        xyt_array = xyt_array.transpose((1,0,2))\n",
        "\n",
        "    mag_video_flatten = np.abs(xyt_array).reshape((xyt_array.shape[0], -1))\n",
        "    _norm_factor = mag_video_flatten.max()\n",
        "    mag_video_flatten = mag_video_flatten/_norm_factor\n",
        "    mag_video_equal = exposure.equalize_adapthist(mag_video_flatten, clip_limit=0.01)\n",
        "    mag_video_equal = mag_video_equal/mag_video_equal.max()\n",
        "    mag_video_equal = mag_video_equal.reshape(xyt_array.shape)\n",
        "    return mag_video_equal\n",
        "\n",
        "ani = None\n",
        "def cine_html5(xyt_array, xlims=None, ylims=None, fig_width=7, equalize=True):\n",
        "    global ani\n",
        "    if isinstance(xyt_array, list):\n",
        "        proc_list = list()\n",
        "        for an_xyt_array in xyt_array:\n",
        "            proc_list.append(equalize_xyt(an_xyt_array) if equalize else an_xyt_array)\n",
        "            \n",
        "        mag_video_equal = np.concatenate(proc_list, axis=1)\n",
        "    else:\n",
        "        if xyt_array.shape[1] < xyt_array.shape[0]:\n",
        "            xyt_array = xyt_array.transpose((1,0,2))\n",
        "\n",
        "        mag_video_flatten = np.abs(xyt_array).reshape((xyt_array.shape[0], -1))\n",
        "        _norm_factor = mag_video_flatten.max()\n",
        "        mag_video_flatten = mag_video_flatten/_norm_factor\n",
        "        mag_video_equal = exposure.equalize_adapthist(mag_video_flatten, clip_limit=0.01)\n",
        "        mag_video_equal = mag_video_equal/mag_video_equal.max()\n",
        "        mag_video_equal = mag_video_equal.reshape(xyt_array.shape)\n",
        "    \n",
        "    plt.ioff()\n",
        "    fig, ax = plt.subplots(figsize=(fig_width,fig_width*mag_video_equal.shape[0]/mag_video_equal.shape[1]))\n",
        "    fig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)\n",
        "    \n",
        "    l = ax.imshow(np.abs(np.squeeze(mag_video_equal)[:,:,0]), cmap='gray', origin='lower', animated=True,\n",
        "                 interpolation='bilinear')\n",
        "    if xlims:\n",
        "        ax.set_xlim(xlims)\n",
        "    if ylims:\n",
        "        ax.set_ylim(ylims)\n",
        "\n",
        "    animate = lambda i: l.set_data(np.abs(np.squeeze(mag_video_equal)[:,:,i]))\n",
        "    num_frame = np.squeeze(mag_video_equal).shape[-1]\n",
        "    ax.set_axis_off()\n",
        "    fig.subplots_adjust(0,0,1,1,0,0)\n",
        "    #fig.tight_layout()\n",
        "    ani = animation.FuncAnimation(fig, animate, frames=num_frame)\n",
        "    plt.close(fig)\n",
        "    plt.ion()\n",
        "    return (HTML(ani.to_jshtml(fps=10, default_mode='loop')), ani)"
      ],
      "metadata": {
        "id": "Z6vLTwrFGJYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Available cines from OCMR dataset\n",
        "  - filter the table by:\n",
        "   1. cases with more than 1 slice\n",
        "   2. fully sampled"
      ],
      "metadata": {
        "id": "V-XTmQIws5RP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ocmr_attributes_DF = pd.read_csv('https://ocmr.s3.amazonaws.com/ocmr_data_attributes.csv')\n",
        "\n",
        "ocmr_attributes_DF.query('slices > 1 and smp == \"fs\"')"
      ],
      "metadata": {
        "id": "RUrRqm8RG9LX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download one particular case"
      ],
      "metadata": {
        "id": "H66gZw3tsi7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "case_name = 'fs_0056_1_5T.h5'"
      ],
      "metadata": {
        "id": "qPTZ-rHBHBws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_download_path = tempfile.TemporaryDirectory(dir='./')\n",
        "download_path = temp_download_path.name\n",
        "bucket_name = 'ocmr'\n",
        "\n",
        "h5_file = f'{download_path}/{case_name}'\n",
        "\n",
        "if not os.path.exists(download_path):\n",
        "    os.makedirs(download_path)\n",
        "\n",
        "# Hook for boto3 client to update tqdm progress bar\n",
        "def hook(t):\n",
        "    def inner(bytes_amount):\n",
        "        t.update(bytes_amount)\n",
        "    return inner\n",
        "\n",
        "s3_client = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
        "# Grab filesize for progress bar updates\n",
        "filesize = boto3.resource('s3', config=Config(signature_version=UNSIGNED)).Object('ocmr', f'data/{case_name}').content_length\n",
        "\n",
        "with tqdm(total=filesize, unit='B', unit_scale=True, desc=case_name) as t:\n",
        "    s3_client.download_file(bucket_name, f'data/{case_name}', h5_file, Callback=hook(t))"
      ],
      "metadata": {
        "id": "g_3zkN-VHDV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read the k-space data and EKG (if available)"
      ],
      "metadata": {
        "id": "ciGAqnxIst11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_data, param, enc, acq_first, noise_scan, twix_ekg = read_ocmr(f'{h5_file}', extrareturns=True)"
      ],
      "metadata": {
        "id": "4mTFEh1ZHJvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reconstruct the cine\n",
        "1. Whiten the data if a noise scan is available\n",
        "2. Coil compress to a smaller number of virtual coils (e.g. 12 virtual coils)\n",
        " - keeping all 30+ coils may become too memory intensive\n",
        " - some network architectures may expect a fixed number of coils (DynamicRadCineMRI expects 12 coils by default)\n",
        "3. Normalize k-space data\n",
        " - different MRI vendors and models, coils, protocols, etc. may produce raw k-space data with different ranges of values\n",
        " - we'll need to normalize them somehow to improve interoperability and agnosticism of our reconstructions\n",
        " - this also helps to make regularization behavior consistent across very different datasets\n",
        " - our strategy is similar to the BART strategy: normalize k-space by some scalar such that the 99th percentile of the naive root-sum-of-squares (RSS) reconstruction of the k-space data is equal to 1.0\n",
        "4. Reconstruct the multi-coil cine (e.g. cine with `X` frames where each frames is comprised of `Y` coil images)\n",
        "5. Estimate the coil sensitivity maps\n",
        "6. Use coil sensitivity information to reduce the multi-coil cine down to a \"normal\" cine\n",
        "  - this uses coil sensitivity information to adaptively combine each multi-coil frame into a single-coil frame"
      ],
      "metadata": {
        "id": "P2t3jxa2s4Yu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def proc_fs_ocmr(all_data, noise_scan=None, n_virtual_coils=None):\n",
        "    # Whiten the data\n",
        "    if noise_scan is not None and noise_scan.size > 0:\n",
        "        noise_scan_nc_nx = np.mean(noise_scan, axis=0)\n",
        "        noise_cov = sp.mri.util.get_cov(noise_scan_nc_nx)\n",
        "    \n",
        "        all_data_whitened = np.zeros_like(all_data, dtype=np.complex64)\n",
        "        for a_slice in trange(all_data.shape[6]):\n",
        "            ksp_nc_nxnynt = all_data.squeeze()[...,a_slice].transpose((2,0,1,3))\n",
        "            ksp_nc_nxnynt = sp.mri.util.whiten(ksp_nc_nxnynt, noise_cov)\n",
        "            all_data_whitened[:,:,0,:,:,0,a_slice,0,0] = ksp_nc_nxnynt.transpose((1,2,0,3))\n",
        "        all_data = all_data_whitened\n",
        "    \n",
        "    ksp_nc_nx_ny_nz_avg = np.mean(all_data.squeeze().transpose((2, 0, 1, 3, 4)), axis=3)\n",
        "    n_coils, n_x, n_y, n_z = ksp_nc_nx_ny_nz_avg.shape\n",
        "    \n",
        "    # Coil compress\n",
        "    if n_virtual_coils is not None:\n",
        "        pca_mtx, neig = coil_pca(ksp_nc_nx_ny_nz_avg.transpose((1,2,3,0)), ncal_x=n_x, ncal_y=n_y, ncal_z=n_z, neig=n_virtual_coils, percentile=99, pca_matrix_only=True)\n",
        "        all_data = apply_pca_weights(all_data.squeeze().transpose((0,1,4,3,2)), pca_mtx, neig=n_virtual_coils)\n",
        "    \n",
        "    # Normalize k-space data\n",
        "    all_data = normalize_kspace(all_data)\n",
        "\n",
        "    # Image space\n",
        "    im_coil_prew = transform.transform_kspace_to_image(all_data[:,:,n_z//2,:,:], [0,1])\n",
        "    # ksp_scale = np.percentile(np.abs(np.sqrt(np.sum(np.power(im_coil_prew[:,:,n_z//2,0,:], 2), axis=2))), 99)\n",
        "    # all_data = all_data/ksp_scale\n",
        "    # im_coil_prew = transform.transform_kspace_to_image(all_data, [0,1])\n",
        "\n",
        "    # Coil Sensitivity Estimation\n",
        "    smaps_return = sp.mri.app.EspiritCalib(np.mean(all_data.transpose((4,0,1,2,3)), axis=4)[...,n_z//2], thresh=0.002, crop=0.98).run()\n",
        "    \n",
        "    # Adaptive coil combination\n",
        "    smaps_na = smaps_return[...,np.newaxis]\n",
        "    #maps_comb = np.sum(im_coil_prew.transpose((4,0,1,2,3))[...,n_z//2,:]*np.conj(smaps_na), axis=0)/np.sum(smaps_na*np.conj(smaps_na), axis=0)\n",
        "    maps_comb = np.sum(im_coil_prew.transpose((3,0,1,2))*np.conj(smaps_na), axis=0)/np.sum(smaps_na*np.conj(smaps_na), axis=0)\n",
        "\n",
        "    maps_comb = np.nan_to_num(maps_comb)\n",
        "    \n",
        "    return maps_comb, smaps_return, all_data, im_coil_prew\n",
        "\n",
        "def normalize_kspace(ksp):\n",
        "    return ksp/np.percentile(np.abs(np.sqrt(np.sum(np.power(transform.transform_kspace_to_image(ksp[:,:,ksp.shape[2]//2,0,:], [0,1]), 2), axis=2))), 99)\n",
        "\n",
        "maps_comb, smaps_return, all_data_proc, im_coil = proc_fs_ocmr(all_data, noise_scan=noise_scan, n_virtual_coils=12)\n",
        "view_cine(maps_comb)"
      ],
      "metadata": {
        "id": "6DM1VqF1HLFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo of the [`DynamicRadCineMRI`](https://github.com/koflera/DynamicRadCineMRI/) Network\n",
        "\n",
        "## Clone the repo to Google Drive\n",
        " - cloning to Google Drive persists the directory across Google Colab sessions\n"
      ],
      "metadata": {
        "id": "QkrC7e6vu6dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/koflera/DynamicRadCineMRI.git /content/drive/MyDrive/DynamicRadCineMRI"
      ],
      "metadata": {
        "id": "PSyTIdxFHMhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#np.percentile(np.abs(np.sqrt(np.sum(np.power(im_coil_prew[:,:,n_z//2,0,:], 2), axis=2))), 99)"
      ],
      "metadata": {
        "id": "KMxKJJsClvml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the OCMR reconstruction from above for use with the `DynamicRadCineMRI` network\n",
        " - save to same Google Drive directory for persistent storage"
      ],
      "metadata": {
        "id": "NcHPCc-FvYMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "complex_cine_file = os.path.join('/content/drive/MyDrive/DynamicRadCineMRI/', case_name.replace('.h5', 'cc.npz'))\n",
        "np.savez(complex_cine_file,\n",
        "         maps_comb_prew_cc=maps_comb, smaps_na_prew_cc=smaps_return, im_coil_prew_cc=im_coil)"
      ],
      "metadata": {
        "id": "eM3YX5TWTmjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies for `DynamicRadCineMRI`"
      ],
      "metadata": {
        "id": "7c9Wm0YOvxsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "sys.path.append('/content/drive/MyDrive/DynamicRadCineMRI/')\n",
        "sys.path.append('/content/drive/MyDrive/DynamicRadCineMRI/network/')\n",
        "from network.nufft_operator import Dyn2DRadEncObj\n",
        "from network.reconstruction_network import NUFFTCascade\n",
        "from network.xtyt_fft_unet import XTYTFFTCNN\n",
        "\n",
        "from helper_funcs.noise_funcs import add_gaussian_noise\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.rcParams['animation.embed_limit'] = 2**128"
      ],
      "metadata": {
        "id": "PDd7t1RMOAue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility function to generate tiny golden angle trajectory"
      ],
      "metadata": {
        "id": "O-PEPmO_Ab4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def return_ga_traj(nX, ntviews, tiny_num=7):\n",
        "    \"\"\"Returns tiny golden angle trajectory and density compensation\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    nX : int\n",
        "        number of readout points\n",
        "    ntviews : int\n",
        "        number of radial spokes/turns\n",
        "    tiny_num : int\n",
        "        type of golden angle, e.g. 7 for 7th tiny golden angle\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    traj : ndarray\n",
        "        trajectory with shape (nX, ntviews)\n",
        "    densitycomp : ndarray\n",
        "\n",
        "    Reference\n",
        "    ---------\n",
        "    https://doi.org/10.1002/mrm.25831\n",
        "\n",
        "    \"\"\"\n",
        "    golden_ratio = (np.sqrt(5.0) + 1.0) / 2.0\n",
        "    golden_angle = np.pi / (golden_ratio + tiny_num - 1)\n",
        "\n",
        "    radian = np.mod(np.arange(0, ntviews) * golden_angle, 2. * np.pi)\n",
        "    rho = np.arange(-np.floor(nX / 2), np.floor(nX / 2)) + 0.5\n",
        "\n",
        "    _sin = np.sin(radian)\n",
        "    _cos = np.cos(radian)\n",
        "\n",
        "    # Complex trajectory\n",
        "    traj = np.stack(((rho[..., np.newaxis] * _sin[np.newaxis, ...]),\n",
        "                     (rho[..., np.newaxis] * _cos[np.newaxis, ...])), axis=2)\n",
        "    \n",
        "    # Density Compensation\n",
        "    densitycomp = np.sqrt(np.power(traj[...,0], 2) + np.power(traj[...,1], 2))\n",
        "    densitycomp /= densitycomp.max()\n",
        "    \n",
        "    # Reshape into (n_spokes, n_readout, 2)\n",
        "    traj = traj.transpose((1,0,2))\n",
        "    \n",
        "    # Reshape into (n_spokes, n_readout)\n",
        "    densitycomp = densitycomp.transpose((1,0))\n",
        "    \n",
        "    return traj, densitycomp"
      ],
      "metadata": {
        "id": "5ill-AS-Qucr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load in the saved OCMR reconstruction and crop the frame dimensions to 320x320"
      ],
      "metadata": {
        "id": "M8CsIDMrAhUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#datatype\n",
        "dtype = torch.float\n",
        "\n",
        "#wheter to use the gpu or not;\n",
        "use_GPU = 1\n",
        "\n",
        "ocmr_fs_load = np.load(complex_cine_file)\n",
        "cine_complex = ocmr_fs_load['maps_comb_prew_cc']\n",
        "n_ro, n_pe, n_frames = cine_complex.shape\n",
        "\n",
        "# Crop to 320x320\n",
        "square_cine = np.zeros((320, 320, n_frames), dtype=np.complex128)\n",
        "if n_ro > 320:\n",
        "    square_cine[:,(320-n_pe)//2:-(320-n_pe)//2,:] = cine_complex[(n_ro-320)//2:-(n_ro-320)//2,...]\n",
        "elif n_ro < 320:\n",
        "    square_cine[(320-n_ro)//2:-(320-n_ro)//2,(320-n_pe)//2:-(320-n_pe)//2,:] = cine_complex\n",
        "else:\n",
        "    square_cine[:,(320-n_pe)//2:-(320-n_pe)//2,:] = cine_complex"
      ],
      "metadata": {
        "id": "0FcKsrjqQxH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load in the coil sensitivity maps and also crop these to 320x320"
      ],
      "metadata": {
        "id": "Djv6IizMApCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a_coil_sense_map = ocmr_fs_load['smaps_na_prew_cc'].squeeze()\n",
        "\n",
        "n_coils_sense, n_ro_sense, n_pe_sense = a_coil_sense_map.shape\n",
        "square_sense_map = np.zeros((n_coils_sense, 320, 320), dtype=np.complex128)\n",
        "\n",
        "if n_ro > 320:\n",
        "    square_sense_map[:, :,(320-n_pe_sense)//2:-(320-n_pe_sense)//2] = a_coil_sense_map[:,(n_ro_sense-320)//2:-(n_ro_sense-320)//2,:]\n",
        "elif n_ro < 320:\n",
        "    square_sense_map[:, (320-n_ro)//2:-(320-n_ro)//2,(320-n_pe_sense)//2:-(320-n_pe_sense)//2] = a_coil_sense_map\n",
        "else:\n",
        "    square_sense_map[:,:,(320-n_pe_sense)//2:-(320-n_pe_sense)//2] = a_coil_sense_map\n",
        "    \n",
        "print(n_coils_sense, n_ro_sense, n_pe_sense, square_sense_map.shape)\n",
        "\n",
        "#convert to tensor of shape (1, 20, 2, 352, 352)\n",
        "csm_tensor = torch.stack([torch.tensor(square_sense_map.real), torch.tensor(square_sense_map.imag)], dim=1).unsqueeze(0)"
      ],
      "metadata": {
        "id": "oRo13-w5Rk3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Radial Trajectory"
      ],
      "metadata": {
        "id": "7sU-MvdhAwnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xf = square_cine\n",
        "im_size = xf.shape\n",
        "\n",
        "#create a torch tensor of shape, e.g. (1,1,2,320,320,n_frames)\n",
        "# would mean there's 23 frames in the cine with 320x320 frames\n",
        "xf_tensor = torch.stack(\n",
        "    [torch.tensor(xf.real), torch.tensor(xf.imag)],\n",
        "    dim=0).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "#for fully-sampled in the radial case, we'd need 320*pi/2 ~ 500 spokes per frame\n",
        "# anything less than that will be considered undersampled (e.g. 96 spokes per frame)\n",
        "spokes_per_frame = 96\n",
        "traj, dc = return_ga_traj(nX=320, ntviews=int(n_frames*spokes_per_frame))\n",
        "ntviews = traj.shape[0]\n",
        "\n",
        "#different NUFFT libraries have their own conventions for the ranges of values\n",
        "# of the trajectory (i.e. coordinates).  In this case, the torchkbnufft expects\n",
        "# pi to be the maximum value, so we scale accordingly\n",
        "traj_scale = np.max((traj[...,0].max(), traj[...,1].max(), traj[...,0].min(), traj[...,1].min()))\n",
        "traj *= np.pi/traj_scale\n",
        "\n",
        "#after retrospective sorting of acquisitions, radial spokes will not be perfectly\n",
        "# sequential and evenly spaced for each frame. We try to simulate this here\n",
        "# by shuffling the radial spokes and then distributing them to each frame, so that\n",
        "# each frame will have spokes that are a bit more randomly distributed and clumpy\n",
        "np.random.seed(20211110)\n",
        "spoke_indices = np.random.choice(traj.shape[0], (n_frames, spokes_per_frame), replace=False)\n",
        "traj = traj[spoke_indices.flatten(),...]\n",
        "# apply the same shuffling to the density compensation\n",
        "dc = dc[spoke_indices.flatten(),...]\n",
        "\n",
        "#convert trajectory to tensor of shape (1,2,Nrad,n_frames)\n",
        "ktraj_tensor = torch.tensor(traj.T.reshape((2,-1,n_frames))).unsqueeze(0)\n",
        "\n",
        "#convert density compensation to tensor of shape (1, 1, 1, Nrad, n_frames)\n",
        "dcomp_tensor = torch.tensor(dc.T.reshape((-1,n_frames))).unsqueeze(0).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "if use_GPU:\n",
        "    xf_tensor = xf_tensor.float().to('cuda')\n",
        "    ktraj_tensor = ktraj_tensor.float().to('cuda')\n",
        "    csm_tensor = csm_tensor.float().to('cuda')\n",
        "    dcomp_tensor = dcomp_tensor.float().to('cuda')"
      ],
      "metadata": {
        "id": "Qo3N0lrjRlcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`fs_0045_3T.h5` with `E3C2K16` suppresses contraction extent"
      ],
      "metadata": {
        "id": "tgY-6MBtCpxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create encoding operator object\n",
        "EncObj = Dyn2DRadEncObj(im_size,\n",
        "                        ktraj_tensor,\n",
        "                        dcomp_tensor,\n",
        "                        csm_tensor,\n",
        "                        norm='ortho').cuda()\n",
        "\n",
        "#define the CNN-block and thus the model;\n",
        "#available: E3C2K4, E3C2K8, E3C2K16;\n",
        "n_enc_stages = 3\n",
        "n_convs_per_stage = 2\n",
        "n_filters = 8\n",
        "CNN = XTYTFFTCNN(n_ch=2,\n",
        "                 n_enc_stages=n_enc_stages,\n",
        "                 n_convs_per_stage=n_convs_per_stage,\n",
        "                 n_filters=n_filters)\n",
        "\n",
        "#initialize reconstruction network\n",
        "reconstruction_network = NUFFTCascade(EncObj,\n",
        "                                      CNN,\n",
        "                                      learn_lambda=False,\n",
        "                                      use_precon=True,\n",
        "                                      mode='fine_tuning').cuda()\n",
        "\n",
        "model_folder = '/content/drive/MyDrive/DynamicRadCineMRI/pre_trained_models/'\n",
        "model_id = 'E{}C{}K{}'.format(n_enc_stages, n_convs_per_stage, n_filters)\n",
        "\n",
        "reconstruction_network.load_state_dict(\n",
        "    torch.load(model_folder + 'model_{}.pt'.format(model_id)))\n",
        "\n",
        "#forward operator which transforms the OCMR cine into (undersampled) radial k-space \n",
        "k_tensor = EncObj.apply_A(xf_tensor)\n",
        "# add some noise\n",
        "k_tensor = add_gaussian_noise(k_tensor, sigma=0.06)\n",
        "\n",
        "#now perform a non-cartesian reconstruction of the radial k-space\n",
        "# this undersampled reconstruction will have all the expected undersampled artifacts\n",
        "xu_tensor = EncObj.apply_Adag(k_tensor)"
      ],
      "metadata": {
        "id": "0xH65XzfRmuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#list of different parameters for nu and npcg as used in the paper\n",
        "nu_list = [10, 14]#[10,12,14] #[1, 1, 2, 4, 8, 12] # the number of alternations between CG- and CNN modules\n",
        "npcg_list = [6, 10]#[6,8,10] #[0, 8, 4, 4, 4, 4] # number of CG iterations in the CG-module\n",
        "\n",
        "#initialize dictionary which contains recos for different hyper-parameters\n",
        "D_cnn_recos = {}\n",
        "n_tests = 6\n",
        "\n",
        "if use_GPU:\n",
        "    xu_tensor = xu_tensor.cuda()\n",
        "    \n",
        "for nu, npcg in tqdm(list(itertools.product(nu_list, npcg_list))):\n",
        "\n",
        "    reconstruction_network.nu = nu\n",
        "    reconstruction_network.npcg = npcg\n",
        "\n",
        "    #apply CNN-block + CG-block\n",
        "    with torch.no_grad():\n",
        "        xcnn_reg = reconstruction_network(xu_tensor.squeeze(0))\n",
        "\n",
        "    if use_GPU:\n",
        "        xcnn_reg = xcnn_reg.cpu()\n",
        "\n",
        "    xcnn_reg = xcnn_reg.squeeze(0).squeeze(0).numpy()\n",
        "    xcnn_reg = xcnn_reg[0, ...] + 1j * xcnn_reg[1, ...]\n",
        "    D_cnn_recos[f'xcnn_nu{nu}_npcg{npcg}'] = xcnn_reg\n",
        "\n",
        "if use_GPU:\n",
        "    xu_tensor = xu_tensor.cpu()\n",
        "\n",
        "xu = xu_tensor.squeeze(0).squeeze(0).cpu().numpy()\n",
        "xu = xu[0, ...] + 1j * xu[1, ...]"
      ],
      "metadata": {
        "id": "v1KcTyrKRoNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization\n",
        "### Left: fully-sampled cartesian reconstruction | Right: under-sampled non-cartesian reconstruction\n",
        " - notice the streaking artifacts on the right that are characteristic of reconstructing from undersampled radial k-space\n",
        " - we're also using indexing to zoom into the central 160x160 of the cine"
      ],
      "metadata": {
        "id": "aNp7lzUsDRW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "view_cine([a_cine[320//4:-320//4,320//4:-320//4,...] for a_cine in [xf, xu]], fig_width=7)"
      ],
      "metadata": {
        "id": "g10PMm56RrAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set the `equalize` flag to `False` to disable adaptive histogram equalization we used above for improving contrast"
      ],
      "metadata": {
        "id": "HmFuLZ3TDhP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "view_cine([a_cine[320//4:-320//4,320//4:-320//4,...] for a_cine in [xf]], fig_width=3.5, equalize=False)"
      ],
      "metadata": {
        "id": "_U7QTMBS27GN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize the outpout of the `DynamicRadCineMRI` network\n",
        "\n",
        "#### Observations for some cases\n",
        "1. Case: `fs_0056_1_5T.h5`\n",
        " - when selecting the pre-trained `E3C2K8` model by setting the following:\n",
        "```python\n",
        "n_enc_stages = 3\n",
        "n_convs_per_stage = 2\n",
        "n_filters = 8\n",
        "```\n",
        "we can see that streaking artifacts are suppressed, but now the LV contraction is oversmoothed such that it no longer contracts to the same extent (the LV chamber doesn't get as small) as the fully-sampled case.  This suggests more tuning is necessary to properly trade-off LV motion fidelity and removal of undersampling streaking artifacts\n",
        "\n"
      ],
      "metadata": {
        "id": "cPtoNh3aDwWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "D_cnn_recos.keys()"
      ],
      "metadata": {
        "id": "k2zOuWN4qRx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "view_cine([a_cine[320//4:-320//4,320//4:-320//4,...] for a_cine in list(D_cnn_recos.values())], fig_width=14, equalize=True)"
      ],
      "metadata": {
        "id": "7XpDm_NlRpg_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}